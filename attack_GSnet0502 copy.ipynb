{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyb/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wyb/miniconda3/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#依赖的包\n",
    "from lib.dataloader import normal_and_generate_dataset_time, get_mask, get_adjacent, get_grid_node_map_maxtrix\n",
    "#攻击函数import\n",
    "from lib.utils_new import mask_loss, compute_loss, predict_and_evaluate, attack, random_attack, fgsm_attack, min_attack\n",
    "from lib.utils_new import saliency, saliency_loss, attack_js, attack_js,attack_saliency,rand_attack\n",
    "from model.GSNet import GSNet\n",
    "from lib.early_stop import EarlyStopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import configparser\n",
    "import pickle as pkl\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#完整运行时会生成txt日志记录#\n",
    "train_log_filename = \"test_log.txt\"\n",
    "train_log_filepath = os.path.join(\"./\", train_log_filename)\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"|%Y-%m-%d, %H:%M:%S| \")\n",
    "\n",
    "#以命令方式运行时会自动设置工作空间\n",
    "#file会报错，应该家’‘\n",
    "curPath = os.path.abspath(os.path.dirname('__file__'))\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "sys.path.append(rootPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#配置文件载入，初始参数记录\n",
    "\n",
    "config_filename = \"config/nyc/GSNet_NYC_Config.json\"\n",
    "with open(config_filename, 'r') as f:\n",
    "    config = json.loads(f.read())\n",
    "# 写入测试超参数\n",
    "with open(train_log_filepath, \"a\") as f:\n",
    "    f.write('测试文件运行时间：'+date_time)\n",
    "    f.write('\\r\\n')\n",
    "    f.write('超参数设置：')\n",
    "    f.write('\\r\\n')\n",
    "    f.write(json.dumps(config, sort_keys=True, indent=4))\n",
    "    f.write('\\r\\n')\n",
    "f.close\n",
    "#GPU设置\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "#文件读取\n",
    "#命令行参数实质上就是赋初始值的作用，可以删除直接赋值就好\n",
    "north_south_map = config['north_south_map']\n",
    "west_east_map = config['west_east_map']\n",
    "\n",
    "all_data_filename = config['all_data_filename']\n",
    "mask_filename = config['mask_filename']\n",
    "\n",
    "road_adj_filename = config['road_adj_filename']\n",
    "risk_adj_filename = config['risk_adj_filename']\n",
    "poi_adj_filename = config['poi_adj_filename']\n",
    "grid_node_filename = config['grid_node_filename']\n",
    "grid_node_map = get_grid_node_map_maxtrix(grid_node_filename)\n",
    "num_of_vertices = grid_node_map.shape[1]\n",
    "\n",
    "\n",
    "patience = config['patience']#用处：\n",
    "delta = config['delta']\n",
    "\n",
    "if config['seed'] is not None:\n",
    "    seed = config['seed']\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "train_rate = config['train_rate']\n",
    "valid_rate = config['valid_rate']\n",
    "\n",
    "recent_prior = config['recent_prior']\n",
    "week_prior = config['week_prior']\n",
    "one_day_period = config['one_day_period']\n",
    "days_of_week = config['days_of_week']\n",
    "pre_len = config['pre_len']\n",
    "seq_len = recent_prior + week_prior\n",
    "\n",
    "training_epoch = config['training_epoch']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原始数据处理\n",
    "all_data.pkl       (8760, 48, 20, 20) 8760=365*24\n",
    "grid_node_map.pkl  (400, 243)  映射矩阵\n",
    "输出特征大小\n",
    "训练集：4584*7*48*20*20\n",
    "验证集：1080*7*48*20*20\n",
    "测试集：1080*7*48*20*20\n",
    "7的含义：t =673时刻是，输入7个时间片，[1, 169, 337, 505, 670, 671, 672]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: (4584, 7, 48, 20, 20) label: (4584, 1, 20, 20) time: (4584, 32) high feature: (1337, 7, 48, 20, 20) high label: (1337, 1, 20, 20)\n",
      "graph_x: (4584, 7, 3, 243) high_graph_x: (1337, 7, 3, 243)\n",
      "feature: (1080, 7, 48, 20, 20) label: (1080, 1, 20, 20) time: (1080, 32) high feature: (315, 7, 48, 20, 20) high label: (315, 1, 20, 20)\n",
      "graph_x: (1080, 7, 3, 243) high_graph_x: (315, 7, 3, 243)\n",
      "x的最大值:7\n",
      "x的最小值:0.0\n",
      "feature: (1080, 7, 48, 20, 20) label: (1080, 1, 20, 20) time: (1080, 32) high feature: (315, 7, 48, 20, 20) high label: (315, 1, 20, 20)\n",
      "graph_x: (1080, 7, 3, 243) high_graph_x: (315, 7, 3, 243)\n",
      "x的最大值:3\n",
      "x的最小值:0.0\n",
      "模型参数---------------------------------------------\n",
      "48 5 7 1 256 32 3 [64, 64]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GSNet(\n",
       "  (st_geo_module): STGeoModule(\n",
       "    (grid_conv): Sequential(\n",
       "      (0): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (grid_gru): GRU(48, 256, num_layers=5, batch_first=True)\n",
       "    (grid_att_fc1): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (grid_att_fc2): Linear(in_features=32, out_features=7, bias=True)\n",
       "    (grid_att_softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (st_sem_module): STSemModule(\n",
       "    (road_gcn): ModuleList(\n",
       "      (0): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (risk_gcn): ModuleList(\n",
       "      (0): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (poi_gcn): ModuleList(\n",
       "      (0): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (graph_gru): GRU(64, 256, num_layers=5, batch_first=True)\n",
       "    (graph_att_fc1): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (graph_att_fc2): Linear(in_features=32, out_features=7, bias=True)\n",
       "    (graph_att_softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (grid_weigth): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (graph_weigth): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (output_layer): Linear(in_features=6400, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = config['batch_size']\n",
    "learning_rate = config['learning_rate']\n",
    "\n",
    "#模型结构\n",
    "num_of_gru_layers = config['num_of_gru_layers']\n",
    "gru_hidden_size = config['gru_hidden_size']\n",
    "gcn_num_filter = config['gcn_num_filter']\n",
    "\n",
    "loaders = []\n",
    "scaler = \"\"\n",
    "train_data_shape = \"\"\n",
    "graph_feature_shape = \"\"\n",
    "   ################## 获取测试数据#########################\n",
    "for idx, (x, y, target_times, high_x, high_y, high_target_times, scaler) in enumerate(normal_and_generate_dataset_time(\n",
    "        all_data_filename,\n",
    "        train_rate=train_rate,\n",
    "        valid_rate=valid_rate,\n",
    "        recent_prior=recent_prior,\n",
    "        week_prior=week_prior,\n",
    "        one_day_period=one_day_period,\n",
    "        days_of_week=days_of_week,\n",
    "        pre_len=pre_len)):\n",
    "    if False:#前100个，没写默认是false\n",
    "        x = x[:100]\n",
    "        y = y[:100]\n",
    "        target_times = target_times[:100]\n",
    "        high_x = high_x[:100]\n",
    "        high_y = high_y[:100]\n",
    "        high_target_times = high_target_times[:100]\n",
    "\n",
    "    if 'nyc' in all_data_filename:\n",
    "        graph_x = x[:, :, [0, 46, 47], :, :].reshape(\n",
    "            (x.shape[0], x.shape[1], -1, north_south_map*west_east_map))#4584*7*3*400,注意reshape和交换维度的不同\n",
    "        high_graph_x = high_x[:, :, [0, 46, 47], :, :].reshape(\n",
    "            (high_x.shape[0], high_x.shape[1], -1, north_south_map*west_east_map))#1337*7*3*400\n",
    "        graph_x = np.dot(graph_x, grid_node_map)#4584*7*3*243\n",
    "        high_graph_x = np.dot(high_graph_x, grid_node_map)\n",
    "    if 'chicago' in all_data_filename:\n",
    "        graph_x = x[:, :, [0, 39, 40], :, :].reshape(\n",
    "            (x.shape[0], x.shape[1], -1, north_south_map*west_east_map))\n",
    "        high_graph_x = high_x[:, :, [0, 39, 40], :, :].reshape(\n",
    "            (high_x.shape[0], high_x.shape[1], -1, north_south_map*west_east_map))\n",
    "        graph_x = np.dot(graph_x, grid_node_map)\n",
    "        high_graph_x = np.dot(high_graph_x, grid_node_map)\n",
    "\n",
    "    print(\"feature:\", str(x.shape), \"label:\", str(y.shape), \"time:\", str(target_times.shape),\n",
    "            \"high feature:\", str(high_x.shape), \"high label:\", str(high_y.shape))\n",
    "    print(\"graph_x:\", str(graph_x.shape),\n",
    "            \"high_graph_x:\", str(high_graph_x.shape))\n",
    "    if idx==2:\n",
    "        np.save('tset_festure.npy',x)\n",
    "    if x.shape[0] ==1080:\n",
    "        b = np.ones_like(x)\n",
    "        b = np.where(x>1,1,0)\n",
    "        print('x的最大值:{}'.format(np.sum(b)))\n",
    "        print('x的最小值:{}'.format(np.min(x)))\n",
    "    if idx == 0:\n",
    "        scaler = scaler\n",
    "        train_data_shape = x.shape\n",
    "        time_shape = target_times.shape\n",
    "        graph_feature_shape = graph_x.shape\n",
    "    loaders.append(Data.DataLoader(\n",
    "        Data.TensorDataset(\n",
    "            torch.from_numpy(x),\n",
    "            torch.from_numpy(target_times),#4584*32\n",
    "            torch.from_numpy(graph_x),\n",
    "            torch.from_numpy(y)\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(idx == 0)\n",
    "    ))\n",
    "    if idx == 2:\n",
    "        high_test_loader = Data.DataLoader(\n",
    "            Data.TensorDataset(\n",
    "                torch.from_numpy(high_x),\n",
    "                torch.from_numpy(high_target_times),\n",
    "                torch.from_numpy(high_graph_x),\n",
    "                torch.from_numpy(high_y)\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=(idx == 0)\n",
    "        )\n",
    "train_loader, val_loader, test_loader = loaders\n",
    "################ 获取测试数据##################\n",
    "nums_of_filter = []\n",
    "for _ in range(2):\n",
    "    nums_of_filter.append(gcn_num_filter)\n",
    "\n",
    "GSNet_Model = GSNet(train_data_shape[2], num_of_gru_layers, seq_len, pre_len,\n",
    "                    gru_hidden_size, time_shape[1], graph_feature_shape[2],\n",
    "                    nums_of_filter, north_south_map, west_east_map)\n",
    "print(\"模型参数---------------------------------------------\")\n",
    "print(train_data_shape[2], num_of_gru_layers, seq_len, pre_len,\n",
    "        gru_hidden_size, time_shape[1], graph_feature_shape[2],\n",
    "        nums_of_filter)\n",
    "\n",
    "# multi gpu\n",
    "if torch.cuda.device_count() > 10:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\", flush=True)\n",
    "    GSNet_Model = nn.DataParallel(GSNet_Model)\n",
    "############### 载入模型######################\n",
    "GSNet_Model.to(device)\n",
    "# print(GSNet_Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载成功！\n",
      "Number of Parameters: 6278578\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#GSNet_Model.load_state_dict(torch.load(\"data/model_parameter.pkl\"))\n",
    "GSNet_Model.load_state_dict(torch.load(\"/home/wyb/mycode/GSNet-master/data/last_model03.pt\"))\n",
    "print(\"模型加载成功！\")\n",
    "\n",
    "num_of_parameters = 0\n",
    "for name, parameters in GSNet_Model.named_parameters():\n",
    "    num_of_parameters += np.prod(parameters.shape)\n",
    "print(\"Number of Parameters: {}\".format(num_of_parameters), flush=True)\n",
    "\n",
    "trainer = optim.Adam(GSNet_Model.parameters(), lr=learning_rate)\n",
    "early_stop = EarlyStopping(patience=patience, delta=delta)\n",
    "\n",
    "risk_mask = get_mask(mask_filename)\n",
    "road_adj = get_adjacent(road_adj_filename)\n",
    "risk_adj = get_adjacent(risk_adj_filename)\n",
    "if poi_adj_filename == \"\":\n",
    "    poi_adj = None\n",
    "else:\n",
    "    poi_adj = get_adjacent(poi_adj_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 09:53:01,559 - INFO - Loading config file from \n"
     ]
    }
   ],
   "source": [
    "#配置log日志输出\n",
    "from myfunction import get_root_logger, logger_info\n",
    "logger = get_root_logger('INFO', './logdata')\n",
    "logger.info(\"Loading config file from \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 10:20:30,248 - INFO - Loading config file from \n",
      "2023-05-06 10:20:30,253 - INFO - ten_ZINBSC_40_35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time,epoch,dataset,model,node_select,method,K,batch size,clean_RMSE,clean_recall,clean_MAP,clean_RCR,adv_RMSE,adv_recall,adv_MAP,adv_RCR,local_adv_RMSE,local_adv_recall,local_adv_MAP,local_adv_RCR,备注信息：特征分析，50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 10:21:12,747 - INFO - Info:  [64/1080 (6%)]\t    adv_RMSE: 6.9999 adv_Recall: 33.3333 adv_MAP: 0.1676 adv_RCR: 0.7204 time:5.081\n",
      "2023-05-06 10:21:23,094 - INFO - Info:  [128/1080 (12%)]\t    adv_RMSE: 8.4086 adv_Recall: 32.5688 adv_MAP: 0.1697 adv_RCR: 0.6621 time:5.068\n",
      "2023-05-06 10:21:33,543 - INFO - Info:  [192/1080 (18%)]\t    adv_RMSE: 8.0346 adv_Recall: 30.4688 adv_MAP: 0.1985 adv_RCR: 0.6737 time:5.106\n",
      "2023-05-06 10:21:44,202 - INFO - Info:  [256/1080 (24%)]\t    adv_RMSE: 7.2421 adv_Recall: 40.4891 adv_MAP: 0.2145 adv_RCR: 0.6494 time:5.427\n",
      "2023-05-06 10:21:55,322 - INFO - Info:  [320/1080 (29%)]\t    adv_RMSE: 7.8084 adv_Recall: 27.5132 adv_MAP: 0.1317 adv_RCR: 0.7375 time:5.386\n",
      "2023-05-06 10:22:06,344 - INFO - Info:  [384/1080 (35%)]\t    adv_RMSE: 8.4682 adv_Recall: 33.4821 adv_MAP: 0.2038 adv_RCR: 0.6875 time:5.492\n",
      "2023-05-06 10:22:16,711 - INFO - Info:  [448/1080 (41%)]\t    adv_RMSE: 7.4248 adv_Recall: 30.1527 adv_MAP: 0.1690 adv_RCR: 0.7131 time:5.198\n",
      "2023-05-06 10:22:27,126 - INFO - Info:  [512/1080 (47%)]\t    adv_RMSE: 8.8803 adv_Recall: 30.0885 adv_MAP: 0.1778 adv_RCR: 0.6821 time:5.132\n",
      "2023-05-06 10:22:37,645 - INFO - Info:  [576/1080 (53%)]\t    adv_RMSE: 8.5725 adv_Recall: 26.5766 adv_MAP: 0.1709 adv_RCR: 0.6992 time:5.217\n",
      "2023-05-06 10:22:49,408 - INFO - Info:  [640/1080 (59%)]\t    adv_RMSE: 8.5309 adv_Recall: 31.7726 adv_MAP: 0.1651 adv_RCR: 0.6562 time:6.392\n",
      "2023-05-06 10:23:02,321 - INFO - Info:  [704/1080 (65%)]\t    adv_RMSE: 9.2314 adv_Recall: 29.1667 adv_MAP: 0.1747 adv_RCR: 0.6975 time:6.322\n",
      "2023-05-06 10:23:12,683 - INFO - Info:  [768/1080 (71%)]\t    adv_RMSE: 5.9753 adv_Recall: 35.6209 adv_MAP: 0.2089 adv_RCR: 0.6663 time:5.126\n",
      "2023-05-06 10:23:22,947 - INFO - Info:  [832/1080 (76%)]\t    adv_RMSE: 6.6394 adv_Recall: 32.9897 adv_MAP: 0.2053 adv_RCR: 0.6562 time:5.022\n",
      "2023-05-06 10:23:33,197 - INFO - Info:  [896/1080 (82%)]\t    adv_RMSE: 7.2889 adv_Recall: 34.6320 adv_MAP: 0.1566 adv_RCR: 0.6372 time:5.061\n",
      "2023-05-06 10:23:43,501 - INFO - Info:  [960/1080 (88%)]\t    adv_RMSE: 9.1287 adv_Recall: 25.0000 adv_MAP: 0.1049 adv_RCR: 0.7896 time:5.029\n",
      "2023-05-06 10:23:53,746 - INFO - Info:  [1024/1080 (94%)]\t    adv_RMSE: 8.3139 adv_Recall: 29.6482 adv_MAP: 0.1818 adv_RCR: 0.6975 time:4.999\n",
      "2023-05-06 10:24:02,702 - INFO - Info:  [1080/1080 (100%)]\t    adv_RMSE: 7.2437 adv_Recall: 25.6410 adv_MAP: 0.1052 adv_RCR: 0.8221 time:3.775\n",
      "2023-05-06 10:24:08,944 - INFO - Info:  不可感知性质：1.8424361944198608\n",
      "2023-05-06 10:24:08,945 - INFO - 攻击时间：Info:time:10.018 \t  clean_RMSE: 7.7257 clean_Recall: 31.8936 clean_MAP: 0.1749 clean_RCR: 0.6876   adv_RMSE: 7.6508 adv_Recall: 32.0888 adv_MAP: 0.1718 adv_RCR: 0.6854\n",
      "2023-05-06 10:24:17,978 - INFO - ten_ZINBSC_40_35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-06 10:24:08,0,NYC,Gsnet,ten,ZINBSC,40,32,7.725744869529572,31.893606637384092,0.17485988553838464,0.6875510412084183,7.650786774511689,32.088823816495854,0.17184742116212604,0.6854468159287408,0.13608585051155955,99.8339521259725,0.9979706094182653,0.00043500937549943134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 10:25:00,479 - INFO - Info:  [64/1080 (6%)]\t    adv_RMSE: 6.9978 adv_Recall: 33.3333 adv_MAP: 0.1669 adv_RCR: 0.7217 time:5.006\n",
      "2023-05-06 10:25:10,843 - INFO - Info:  [128/1080 (12%)]\t    adv_RMSE: 8.4037 adv_Recall: 32.1101 adv_MAP: 0.1673 adv_RCR: 0.6693 time:5.017\n",
      "2023-05-06 10:25:20,966 - INFO - Info:  [192/1080 (18%)]\t    adv_RMSE: 8.0257 adv_Recall: 30.0781 adv_MAP: 0.1967 adv_RCR: 0.6604 time:5.001\n",
      "2023-05-06 10:25:31,167 - INFO - Info:  [256/1080 (24%)]\t    adv_RMSE: 7.2447 adv_Recall: 38.8587 adv_MAP: 0.2034 adv_RCR: 0.6566 time:5.028\n",
      "2023-05-06 10:25:41,636 - INFO - Info:  [320/1080 (29%)]\t    adv_RMSE: 7.7990 adv_Recall: 28.5714 adv_MAP: 0.1335 adv_RCR: 0.7217 time:5.164\n",
      "2023-05-06 10:25:54,646 - INFO - Info:  [384/1080 (35%)]\t    adv_RMSE: 8.4715 adv_Recall: 33.9286 adv_MAP: 0.2055 adv_RCR: 0.6840 time:6.370\n",
      "2023-05-06 10:26:07,513 - INFO - Info:  [448/1080 (41%)]\t    adv_RMSE: 7.4300 adv_Recall: 29.0076 adv_MAP: 0.1619 adv_RCR: 0.7071 time:6.325\n",
      "2023-05-06 10:26:19,276 - INFO - Info:  [512/1080 (47%)]\t    adv_RMSE: 8.8717 adv_Recall: 31.4159 adv_MAP: 0.1832 adv_RCR: 0.6874 time:5.113\n",
      "2023-05-06 10:26:29,747 - INFO - Info:  [576/1080 (53%)]\t    adv_RMSE: 8.5798 adv_Recall: 27.9279 adv_MAP: 0.1822 adv_RCR: 0.6955 time:5.157\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m ack_map \u001b[39m=\u001b[39m node_map(i,chi_k,out_K, cfgin, GSNet_Model, test_loader, risk_mask, road_adj, risk_adj, poi_adj,\n\u001b[1;32m     40\u001b[0m                     grid_node_map, device, data_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnyc\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39m# 2. 攻击方法选择，返回未攻击后的预测值，标签值,攻击前的预测值，攻击过程打印每个信息\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m adv_val_predict, val_target, val_predict \u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39m{0}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(parm_att))(logger, cfgin, ack_map, GSNet_Model, test_loader,  road_adj, risk_adj, poi_adj,\n\u001b[1;32m     43\u001b[0m                                                                         grid_node_map, scaler, risk_mask, device, data_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnyc\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     44\u001b[0m \u001b[39m#计算结果并打印、存储,注意表头信息需要传递参数\u001b[39;00m\n\u001b[1;32m     45\u001b[0m log_test_csv_time_K(epoch,out_K,adv_val_predict, val_target,\n\u001b[1;32m     46\u001b[0m                     val_predict,cfgin,i,j,file_name,risk_mask)\n",
      "File \u001b[0;32m~/mycode/GSNet-master/lib/Imperceptible_attack.py:2244\u001b[0m, in \u001b[0;36mZINBSC\u001b[0;34m(logger, cfgs, map, net, dataloader, road_adj, risk_adj, poi_adj, grid_node_map, scaler, risk_mask, device, data_type)\u001b[0m\n\u001b[1;32m   2242\u001b[0m feature\u001b[39m.\u001b[39mretain_grad()\n\u001b[1;32m   2243\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m-> 2244\u001b[0m     loss \u001b[39m=\u001b[39m kl_div_pro(net(feature, target_time, graph_feature, road_adj, risk_adj, poi_adj,\n\u001b[1;32m   2245\u001b[0m                       grid_node_map),  label,risk_mask_use)\n\u001b[1;32m   2246\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2248\u001b[0m X_pgd \u001b[39m=\u001b[39m feature  \u001b[39m# 脱裤子放屁..\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mycode/GSNet-master/model/GSNet.py:259\u001b[0m, in \u001b[0;36mGSNet.forward\u001b[0;34m(self, grid_input, target_time_feature, graph_feature, road_adj, risk_adj, poi_adj, grid_node_map)\u001b[0m\n\u001b[1;32m    256\u001b[0m batch_size,_,_,_,_ \u001b[39m=\u001b[39mgrid_input\u001b[39m.\u001b[39mshape\n\u001b[1;32m    258\u001b[0m grid_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mst_geo_module(grid_input,target_time_feature)\n\u001b[0;32m--> 259\u001b[0m graph_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mst_sem_module(graph_feature,road_adj,risk_adj,poi_adj,\n\u001b[1;32m    260\u001b[0m                                 target_time_feature,grid_node_map)\n\u001b[1;32m    262\u001b[0m grid_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_weigth(grid_output)\n\u001b[1;32m    263\u001b[0m graph_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_weigth(graph_output)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mycode/GSNet-master/model/GSNet.py:168\u001b[0m, in \u001b[0;36mSTSemModule.forward\u001b[0;34m(self, graph_feature, road_adj, risk_adj, poi_adj, target_time_feature, grid_node_map)\u001b[0m\n\u001b[1;32m    166\u001b[0m road_graph_output \u001b[39m=\u001b[39m graph_feature\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,D1,N)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    167\u001b[0m \u001b[39mfor\u001b[39;00m gcn_layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroad_gcn:\n\u001b[0;32m--> 168\u001b[0m     road_graph_output \u001b[39m=\u001b[39m gcn_layer(road_graph_output,road_adj)\n\u001b[1;32m    170\u001b[0m risk_graph_output \u001b[39m=\u001b[39m graph_feature\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,D1,N)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m gcn_layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrisk_gcn:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mycode/GSNet-master/model/GSNet.py:39\u001b[0m, in \u001b[0;36mGCN_Layer.forward\u001b[0;34m(self, input, adj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"计算一层GCN\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m    {Tensor} -- output,shape (batch_size,N,num_of_filter)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m batch_size,_,_ \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape\n\u001b[0;32m---> 39\u001b[0m adj \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(adj)\u001b[39m.\u001b[39;49mto(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     40\u001b[0m adj \u001b[39m=\u001b[39m adj\u001b[39m.\u001b[39mrepeat(batch_size,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(adj, \u001b[39minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#攻击，并写入数据,20230315导入包修改为lib.utils_new_round\n",
    "import yaml\n",
    "from mmcv import Config\n",
    "from myfunction import log_test_results\n",
    "from lib.Imperceptible_attack import log_test_csv,node_map,prenoise_pgd,rcr_pgd,fgsm,min,kl_pgd,JS_pgd_impr,rand_attack,nonenoise_pgd\n",
    "from lib.Imperceptible_attack import ZINBSC,fgsm_impr,min_impr,pgd_impr,random_impr,log_test_csv_time_K,ZINBSC_geneater_kk\n",
    "from myfunction import get_root_logger, logger_info,kl_div_pro\n",
    "from lib.admm_atack_new import none_admm_attack\n",
    "from lib.distru_attack import none_distri_attack\n",
    "from lib.vers_attack import vers_attack\n",
    "from lib.select import select_attack\n",
    "#配置logo\n",
    "logger = get_root_logger('INFO', './logdata')\n",
    "logger.info(\"Loading config file from \")\n",
    "cfgin = Config.fromfile('attack_setting.yaml')\n",
    "#根据配置选择攻击方法\n",
    "if cfgin.attacker == 'white_attacker':\n",
    "    header = ['time','epoch','dataset', 'model','node_select', 'method', 'K','batch size', \n",
    "              'clean_RMSE', 'clean_recall', 'clean_MAP', 'clean_RCR',\n",
    "              'adv_RMSE', 'adv_recall', 'adv_MAP', 'adv_RCR',\n",
    "              'local_adv_RMSE', 'local_adv_recall', 'local_adv_MAP', 'local_adv_RCR',\n",
    "              '备注信息：特征分析，50']\n",
    "    #文件名\n",
    "    file_name = '第25次-{}-eps{}-model-{}'.format(\n",
    "        cfgin.dataset, cfgin.test_epsilon, cfgin.backbone)\n",
    "    log_test_results(cfgin.result_dir, header, file_name)\n",
    "    #可能的时间循环\n",
    "    #攻击方法+节点选择组合\n",
    "    for epoch in range(1):\n",
    "        for out_K in cfgin.K:\n",
    "            for i in cfgin.select_node:\n",
    "                for j in cfgin.attack_method:\n",
    "                    for chi_k in range(35,36):\n",
    "                        logger.info(i+'_'+j+\"_\"+str(out_K)+\"_\"+str(chi_k))\n",
    "                        parm_att = j #攻击方法的函数名称\n",
    "                        parm_node = i #节点选择的方法\n",
    "                        #进行攻击,输出攻击日志\n",
    "                        # 1. 节点选择，返回攻击的节点\n",
    "                        ack_map = node_map(i,chi_k,out_K, cfgin, GSNet_Model, test_loader, risk_mask, road_adj, risk_adj, poi_adj,\n",
    "                                            grid_node_map, device, data_type='nyc')\n",
    "                        # 2. 攻击方法选择，返回未攻击后的预测值，标签值,攻击前的预测值，攻击过程打印每个信息\n",
    "                        adv_val_predict, val_target, val_predict = eval(\"{0}\".format(parm_att))(logger, cfgin, ack_map, GSNet_Model, test_loader,  road_adj, risk_adj, poi_adj,\n",
    "                                                                                                grid_node_map, scaler, risk_mask, device, data_type='nyc')\n",
    "                        #计算结果并打印、存储,注意表头信息需要传递参数\n",
    "                        log_test_csv_time_K(epoch,out_K,adv_val_predict, val_target,\n",
    "                                            val_predict,cfgin,i,j,file_name,risk_mask)\n",
    "                        torch.cuda.empty_cache()\n",
    "    for epoch in range(2):\n",
    "        for out_K in cfgin.K:\n",
    "            i = 'ten'\n",
    "            j = 'ZINBSC'\n",
    "            for chi_k in range(10,45):\n",
    "                logger.info(i+'_'+j+\"_\"+str(out_K)+\"_\"+str(chi_k))\n",
    "                parm_att = j #攻击方法的函数名称\n",
    "                parm_node = i #节点选择的方法\n",
    "                #进行攻击,输出攻击日志\n",
    "                # 1. 节点选择，返回攻击的节点\n",
    "                ack_map = node_map(i,chi_k,out_K, cfgin, GSNet_Model, test_loader, risk_mask, road_adj, risk_adj, poi_adj,\n",
    "                                    grid_node_map, device, data_type='nyc')\n",
    "                # 2. 攻击方法选择，返回未攻击后的预测值，标签值,攻击前的预测值，攻击过程打印每个信息\n",
    "                adv_val_predict, val_target, val_predict = eval(\"{0}\".format(parm_att))(logger, cfgin, ack_map, GSNet_Model, test_loader,  road_adj, risk_adj, poi_adj,\n",
    "                                                                                        grid_node_map, scaler, risk_mask, device, data_type='nyc')\n",
    "                #计算结果并打印、存储,注意表头信息需要传递参数\n",
    "                log_test_csv_time_K(epoch,out_K,adv_val_predict, val_target,\n",
    "                                    val_predict,cfgin,i,j,file_name,risk_mask)\n",
    "                torch.cuda.empty_cache()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "aso = np.load('riak_243.npy')\n",
    "bso = np.load('map_0502.npy')\n",
    "\n",
    "print(aso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(aso[\u001b[39m38\u001b[39;49m,:,:])\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39msum(aso[\u001b[39m38\u001b[39m,:,:]))\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "print(aso[38,:,:])\n",
    "print(np.sum(aso[38,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        1.8399999 0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        1.8399999 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(bso[100,1,0,:,:]*46.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 20, 20)\n",
      "(20, 20)\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.62786906e-04\n",
      "  3.97200063e-02 0.00000000e+00 2.05111504e-02 7.17890263e-02\n",
      "  3.09295137e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.51147636e-03\n",
      "  1.00927882e-01 1.03369690e-01 1.52856916e-01 1.56438217e-01\n",
      "  1.00927882e-01 5.53475507e-03 1.62786906e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.25573812e-04 1.40485108e-01\n",
      "  2.64040381e-01 2.17808887e-01 1.54647559e-01 1.28113300e-01\n",
      "  9.01839510e-02 6.99983723e-03 3.25573812e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.08204463e-01 1.81670189e-01\n",
      "  2.68598408e-01 2.14878723e-01 1.26973793e-01 1.46508217e-01\n",
      "  6.23473860e-02 7.48819811e-03 7.32541084e-03 8.46491940e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.89288622e-02 2.45645449e-01 2.30017900e-01\n",
      "  1.92576915e-01 2.00065121e-01 1.64251998e-01 1.31531820e-01\n",
      "  6.96728006e-02 3.74409892e-02 0.00000000e+00 1.13950833e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.48819811e-03 2.80644625e-01 3.78642350e-01 2.83249229e-01\n",
      "  1.48950025e-01 1.14601985e-01 1.82321332e-02 3.12550887e-02\n",
      "  4.88360738e-03 1.85577087e-02 6.51147624e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.41575778e-01 1.75972655e-01 3.10434639e-01 5.69754187e-03\n",
      "  5.04639419e-03 0.00000000e+00 0.00000000e+00 2.53947582e-02\n",
      "  2.53947582e-02 3.10923010e-02 1.30229527e-02 9.11606662e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.04297572e-01\n",
      "  3.79781872e-01 4.85756159e-01 8.87188688e-02 1.43578053e-01\n",
      "  9.18118209e-02 7.30913207e-02 3.67898419e-02 2.26273816e-02\n",
      "  8.23701769e-02 1.09555595e-01 5.22545986e-02 5.45336157e-02\n",
      "  8.13934579e-03 3.76037769e-02 1.26973791e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 9.49047729e-02 9.77535427e-01\n",
      "  1.00000000e+00 3.05713832e-01 1.96972162e-01 2.14553148e-01\n",
      "  1.93553641e-01 2.64203161e-01 2.38320038e-01 9.01839510e-02\n",
      "  2.27087736e-01 1.10857889e-01 8.85560811e-02 7.60214850e-02\n",
      "  9.50675532e-02 1.90460682e-02 2.63714790e-02 3.80921364e-02]\n",
      " [0.00000000e+00 0.00000000e+00 2.02832490e-01 6.36985183e-01\n",
      "  3.40550214e-01 1.01741821e-01 1.33648053e-01 1.53019696e-01\n",
      "  1.02555752e-01 1.33322477e-01 2.47598886e-01 1.21439040e-01\n",
      "  3.36968899e-02 8.83932933e-02 6.73937798e-02 5.04639409e-02\n",
      "  3.53247598e-02 5.29057458e-02 4.86732870e-02 6.60914853e-02]\n",
      " [0.00000000e+00 0.00000000e+00 3.62852037e-01 6.92658305e-01\n",
      "  1.18671656e-01 2.31808558e-01 2.02344134e-01 7.04867318e-02\n",
      "  1.45694286e-01 6.72309920e-02 8.28585401e-02 1.27462149e-01\n",
      "  9.75093618e-02 1.01741821e-01 1.34299204e-01 9.14862454e-02\n",
      "  1.17043793e-01 1.07113786e-01 5.81149273e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.17190334e-02 2.36854956e-01\n",
      "  2.00879052e-01 2.81784147e-01 2.73156434e-01 2.56063819e-01\n",
      "  1.88832819e-01 6.75565675e-02 5.66498451e-02 1.19973958e-01\n",
      "  1.57252163e-01 1.78251669e-01 1.92576915e-01 9.05095264e-02\n",
      "  9.11606699e-02 9.65326354e-02 3.28829549e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.99755815e-02 1.53996423e-01\n",
      "  3.76851708e-01 3.40550214e-01 2.92853653e-01 2.93667585e-01\n",
      "  3.18736762e-01 2.09995121e-01 1.85577080e-01 2.07553312e-01\n",
      "  1.13462478e-01 1.20136738e-01 1.03369690e-01 8.67654234e-02\n",
      "  9.19746086e-02 7.01611564e-02 4.57431227e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.23701769e-02 1.40647888e-01\n",
      "  7.26029649e-02 3.22969228e-01 2.79342353e-01 3.87432843e-01\n",
      "  2.14553148e-01 2.42552504e-01 9.11606699e-02 2.42552496e-02\n",
      "  7.17890263e-02 4.54175472e-02 2.81621367e-02 6.99983686e-02\n",
      "  1.28927231e-01 1.19648382e-01 4.93244343e-02 0.00000000e+00]\n",
      " [0.00000000e+00 7.71609992e-02 2.71854132e-01 1.96483806e-01\n",
      "  2.13576421e-01 2.59807914e-01 1.98111668e-01 2.53296435e-01\n",
      "  1.97948888e-01 8.51375535e-02 5.86032867e-03 0.00000000e+00\n",
      "  3.09295137e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.18834442e-02 8.13934545e-04 0.00000000e+00]\n",
      " [4.39524651e-03 1.48136094e-01 1.43903628e-01 1.76461011e-01\n",
      "  1.89158395e-01 1.70437902e-01 1.67507738e-01 1.34461984e-01\n",
      "  3.28829549e-02 5.86032867e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.86032867e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.74409906e-03 6.47891909e-02 1.85739860e-01\n",
      "  1.52694121e-01 2.48087257e-01 9.89744440e-02 5.14406636e-02\n",
      "  1.62786916e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.48136094e-02 5.37196826e-03 1.17206573e-02\n",
      "  8.70909989e-02 4.49291877e-02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.44180369e-03 5.89288622e-02\n",
      "  1.37229368e-01 1.97948888e-01 7.58586973e-02 3.41852522e-03\n",
      "  0.00000000e+00 2.76737753e-03 1.62786906e-04 1.23718055e-02\n",
      "  2.29529552e-02 3.06039397e-02 2.24645939e-02 2.11622994e-02\n",
      "  0.00000000e+00 1.62786906e-04 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.30229525e-03 1.18834442e-02\n",
      "  1.62786906e-04 0.00000000e+00 0.00000000e+00 1.95344305e-03\n",
      "  2.27901665e-03 1.62786906e-04 1.13950833e-03 1.79065601e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.25573812e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "aa = pd.read_pickle('accident_value.pkl')\n",
    "print(aa.shape)\n",
    "bb = np.sum(aa,axis=0)\n",
    "print(bb.shape)\n",
    "cc = np.array(bb/np.max(bb)).astype(np.float32)\n",
    "print(cc)\n",
    "print(np.max(cc))\n",
    "np.save('weight_nyc.npy',cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n"
     ]
    }
   ],
   "source": [
    "map_243 = np.load(\"data/nyc/243nyc.npy\")\n",
    "print(map_243.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (20) must match the size of tensor b (10) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnonzero(map_a  \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39mif\u001b[39;00m idx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m>\u001b[39m\u001b[39m20\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m     map_a[idx[:\u001b[39m10\u001b[39;49m,:]]\u001b[39m==\u001b[39;49mmap_b \n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(map_a)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (20) must match the size of tensor b (10) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "map_a = torch.randint(0,2,(20,20))\n",
    "map_b = torch.randint(10,11,(1,10))\n",
    "\n",
    "idx = torch.nonzero(map_a  == 1)\n",
    "if idx.shape[0]>20:\n",
    "    map_a[idx[:10,:]]==map_b \n",
    "print(map_a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.randint(1,3,(2,3))\n",
    "b=torch.randint(1,3,(2,3))\n",
    "c = []\n",
    "c.append(a)\n",
    "c.append(b)\n",
    "\n",
    "print(torch.stack(c).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 1]\n",
      " [1 2 1]\n",
      " [2 2 1]\n",
      " [1 2 1]]\n",
      "[[1 2 1]\n",
      " [1 2 1]\n",
      " [2 2 1]\n",
      " [1 2 1]]\n",
      "[[1 2 1]\n",
      " [1 2 1]\n",
      " [2 2 1]\n",
      " [1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "import  numpy as np\n",
    "a=np.random.randint(1,3,(2,3))\n",
    "b=np.random.randint(1,3,(2,3))\n",
    "c = []\n",
    "c.append(a)\n",
    "c.append(b)\n",
    "\n",
    "print(np.vstack(c))\n",
    "print(np.concatenate([a,b],axis=0))\n",
    "print(np.concatenate(c,axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
