{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyb/miniconda3/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#依赖的包\n",
    "from lib.dataloader import normal_and_generate_dataset_time, get_mask, get_adjacent, get_grid_node_map_maxtrix\n",
    "#攻击函数import\n",
    "from lib.utils_new import mask_loss, compute_loss, predict_and_evaluate, attack, random_attack, fgsm_attack, min_attack\n",
    "from lib.utils_new import saliency, saliency_loss, attack_js, attack_js,attack_saliency,rand_attack\n",
    "from model.GSNet import GSNet\n",
    "from lib.early_stop import EarlyStopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import configparser\n",
    "import pickle as pkl\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_log_filename = \"test_log.txt\"\n",
    "train_log_filepath = os.path.join(\"./\", train_log_filename)\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"|%Y-%m-%d, %H:%M:%S| \")\n",
    "\n",
    "curPath = os.path.abspath(os.path.dirname('__file__'))\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "sys.path.append(rootPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "config_filename = \"config/nyc/GSNet_NYC_Config.json\"\n",
    "with open(config_filename, 'r') as f:\n",
    "    config = json.loads(f.read())\n",
    "# 写入测试超参数\n",
    "with open(train_log_filepath, \"a\") as f:\n",
    "    f.write('测试文件运行时间：'+date_time)\n",
    "    f.write('\\r\\n')\n",
    "    f.write('超参数设置：')\n",
    "    f.write('\\r\\n')\n",
    "    f.write(json.dumps(config, sort_keys=True, indent=4))\n",
    "    f.write('\\r\\n')\n",
    "f.close\n",
    "#GPU设置\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "#文件读取\n",
    "#命令行参数实质上就是赋初始值的作用，可以删除直接赋值就好\n",
    "north_south_map = config['north_south_map']\n",
    "west_east_map = config['west_east_map']\n",
    "\n",
    "all_data_filename = config['all_data_filename']\n",
    "mask_filename = config['mask_filename']\n",
    "\n",
    "road_adj_filename = config['road_adj_filename']\n",
    "risk_adj_filename = config['risk_adj_filename']\n",
    "poi_adj_filename = config['poi_adj_filename']\n",
    "grid_node_filename = config['grid_node_filename']\n",
    "grid_node_map = get_grid_node_map_maxtrix(grid_node_filename)\n",
    "num_of_vertices = grid_node_map.shape[1]\n",
    "\n",
    "\n",
    "patience = config['patience']#用处：\n",
    "delta = config['delta']\n",
    "\n",
    "if config['seed'] is not None:\n",
    "    seed = config['seed']\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "train_rate = config['train_rate']\n",
    "valid_rate = config['valid_rate']\n",
    "\n",
    "recent_prior = config['recent_prior']\n",
    "week_prior = config['week_prior']\n",
    "one_day_period = config['one_day_period']\n",
    "days_of_week = config['days_of_week']\n",
    "pre_len = config['pre_len']\n",
    "seq_len = recent_prior + week_prior\n",
    "\n",
    "training_epoch = config['training_epoch']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: (4584, 7, 48, 20, 20) label: (4584, 1, 20, 20) time: (4584, 32) high feature: (1337, 7, 48, 20, 20) high label: (1337, 1, 20, 20)\n",
      "graph_x: (4584, 7, 3, 243) high_graph_x: (1337, 7, 3, 243)\n",
      "feature: (1080, 7, 48, 20, 20) label: (1080, 1, 20, 20) time: (1080, 32) high feature: (315, 7, 48, 20, 20) high label: (315, 1, 20, 20)\n",
      "graph_x: (1080, 7, 3, 243) high_graph_x: (315, 7, 3, 243)\n",
      "x的最大值:7\n",
      "x的最小值:0.0\n",
      "feature: (1080, 7, 48, 20, 20) label: (1080, 1, 20, 20) time: (1080, 32) high feature: (315, 7, 48, 20, 20) high label: (315, 1, 20, 20)\n",
      "graph_x: (1080, 7, 3, 243) high_graph_x: (315, 7, 3, 243)\n",
      "x的最大值:3\n",
      "x的最小值:0.0\n",
      "---------------------------------------------\n",
      "48 5 7 1 256 32 3 [64, 64]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GSNet(\n",
       "  (st_geo_module): STGeoModule(\n",
       "    (grid_conv): Sequential(\n",
       "      (0): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (grid_gru): GRU(48, 256, num_layers=5, batch_first=True)\n",
       "    (grid_att_fc1): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (grid_att_fc2): Linear(in_features=32, out_features=7, bias=True)\n",
       "    (grid_att_softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (st_sem_module): STSemModule(\n",
       "    (road_gcn): ModuleList(\n",
       "      (0): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (risk_gcn): ModuleList(\n",
       "      (0): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (poi_gcn): ModuleList(\n",
       "      (0): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): GCN_Layer(\n",
       "        (gcn_layer): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (graph_gru): GRU(64, 256, num_layers=5, batch_first=True)\n",
       "    (graph_att_fc1): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (graph_att_fc2): Linear(in_features=32, out_features=7, bias=True)\n",
       "    (graph_att_softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (grid_weigth): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (graph_weigth): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (output_layer): Linear(in_features=6400, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = config['batch_size']\n",
    "learning_rate = config['learning_rate']\n",
    "\n",
    "#模型结构\n",
    "num_of_gru_layers = config['num_of_gru_layers']\n",
    "gru_hidden_size = config['gru_hidden_size']\n",
    "gcn_num_filter = config['gcn_num_filter']\n",
    "\n",
    "loaders = []\n",
    "scaler = \"\"\n",
    "train_data_shape = \"\"\n",
    "graph_feature_shape = \"\"\n",
    "\n",
    "for idx, (x, y, target_times, high_x, high_y, high_target_times, scaler) in enumerate(normal_and_generate_dataset_time(\n",
    "        all_data_filename,\n",
    "        train_rate=train_rate,\n",
    "        valid_rate=valid_rate,\n",
    "        recent_prior=recent_prior,\n",
    "        week_prior=week_prior,\n",
    "        one_day_period=one_day_period,\n",
    "        days_of_week=days_of_week,\n",
    "        pre_len=pre_len)):\n",
    "    if False:#前100个，没写默认是false\n",
    "        x = x[:100]\n",
    "        y = y[:100]\n",
    "        target_times = target_times[:100]\n",
    "        high_x = high_x[:100]\n",
    "        high_y = high_y[:100]\n",
    "        high_target_times = high_target_times[:100]\n",
    "\n",
    "    if 'nyc' in all_data_filename:\n",
    "        graph_x = x[:, :, [0, 46, 47], :, :].reshape(\n",
    "            (x.shape[0], x.shape[1], -1, north_south_map*west_east_map))#4584*7*3*400,注意reshape和交换维度的不同\n",
    "        high_graph_x = high_x[:, :, [0, 46, 47], :, :].reshape(\n",
    "            (high_x.shape[0], high_x.shape[1], -1, north_south_map*west_east_map))#1337*7*3*400\n",
    "        graph_x = np.dot(graph_x, grid_node_map)#4584*7*3*243\n",
    "        high_graph_x = np.dot(high_graph_x, grid_node_map)\n",
    "    if 'chicago' in all_data_filename:\n",
    "        graph_x = x[:, :, [0, 39, 40], :, :].reshape(\n",
    "            (x.shape[0], x.shape[1], -1, north_south_map*west_east_map))\n",
    "        high_graph_x = high_x[:, :, [0, 39, 40], :, :].reshape(\n",
    "            (high_x.shape[0], high_x.shape[1], -1, north_south_map*west_east_map))\n",
    "        graph_x = np.dot(graph_x, grid_node_map)\n",
    "        high_graph_x = np.dot(high_graph_x, grid_node_map)\n",
    "\n",
    "    print(\"feature:\", str(x.shape), \"label:\", str(y.shape), \"time:\", str(target_times.shape),\n",
    "            \"high feature:\", str(high_x.shape), \"high label:\", str(high_y.shape))\n",
    "    print(\"graph_x:\", str(graph_x.shape),\n",
    "            \"high_graph_x:\", str(high_graph_x.shape))\n",
    "    if idx==2:\n",
    "        np.save('tset_festure.npy',x)\n",
    "    if x.shape[0] ==1080:\n",
    "        b = np.ones_like(x)\n",
    "        b = np.where(x>1,1,0)\n",
    "    if idx == 0:\n",
    "        scaler = scaler\n",
    "        train_data_shape = x.shape\n",
    "        time_shape = target_times.shape\n",
    "        graph_feature_shape = graph_x.shape\n",
    "    loaders.append(Data.DataLoader(\n",
    "        Data.TensorDataset(\n",
    "            torch.from_numpy(x),\n",
    "            torch.from_numpy(target_times),#4584*32\n",
    "            torch.from_numpy(graph_x),\n",
    "            torch.from_numpy(y)\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(idx == 0)\n",
    "    ))\n",
    "    if idx == 2:\n",
    "        high_test_loader = Data.DataLoader(\n",
    "            Data.TensorDataset(\n",
    "                torch.from_numpy(high_x),\n",
    "                torch.from_numpy(high_target_times),\n",
    "                torch.from_numpy(high_graph_x),\n",
    "                torch.from_numpy(high_y)\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=(idx == 0)\n",
    "        )\n",
    "train_loader, val_loader, test_loader = loaders\n",
    "################ 获取测试数据##################\n",
    "nums_of_filter = []\n",
    "for _ in range(2):\n",
    "    nums_of_filter.append(gcn_num_filter)\n",
    "\n",
    "GSNet_Model = GSNet(train_data_shape[2], num_of_gru_layers, seq_len, pre_len,\n",
    "                    gru_hidden_size, time_shape[1], graph_feature_shape[2],\n",
    "                    nums_of_filter, north_south_map, west_east_map)\n",
    "print(\"---------------------------------------------\")\n",
    "print(train_data_shape[2], num_of_gru_layers, seq_len, pre_len,\n",
    "        gru_hidden_size, time_shape[1], graph_feature_shape[2],\n",
    "        nums_of_filter)\n",
    "\n",
    "\n",
    "# multi gpu\n",
    "if torch.cuda.device_count() > 10:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\", flush=True)\n",
    "    GSNet_Model = nn.DataParallel(GSNet_Model)\n",
    "############### 载入模型######################\n",
    "GSNet_Model.to(device)\n",
    "# print(GSNet_Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载成功！\n",
      "Number of Parameters: 6278578\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GSNet_Model.load_state_dict(torch.load(\"data/model38.pt\"))\n",
    "print(\"模型加载成功！\")\n",
    "\n",
    "num_of_parameters = 0\n",
    "for name, parameters in GSNet_Model.named_parameters():\n",
    "    num_of_parameters += np.prod(parameters.shape)\n",
    "print(\"Number of Parameters: {}\".format(num_of_parameters), flush=True)\n",
    "\n",
    "trainer = optim.Adam(GSNet_Model.parameters(), lr=learning_rate)\n",
    "early_stop = EarlyStopping(patience=patience, delta=delta)\n",
    "\n",
    "risk_mask = get_mask(mask_filename)\n",
    "road_adj = get_adjacent(road_adj_filename)\n",
    "risk_adj = get_adjacent(risk_adj_filename)\n",
    "if poi_adj_filename == \"\":\n",
    "    poi_adj = None\n",
    "else:\n",
    "    poi_adj = get_adjacent(poi_adj_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:06:22,410 - INFO - Loading config file from \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from lib.myfunction import get_root_logger, logger_info\n",
    "logger = get_root_logger('INFO', './logdata')\n",
    "logger.info(\"Loading config file from \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:09:10,714 - INFO - Loading config file from \n",
      "2023-05-09 15:09:10,718 - INFO - ten_ZINBSC_40_35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time,epoch,dataset,model,node_select,method,K,batch size,clean_RMSE,clean_recall,clean_MAP,clean_RCR,adv_RMSE,adv_recall,adv_MAP,adv_RCR,local_adv_RMSE,local_adv_recall,local_adv_MAP,local_adv_RCR,备注信息：特征分析，50\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.91 GiB (GPU 0; 10.76 GiB total capacity; 6.83 GiB already allocated; 2.52 GiB free; 7.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m parm_node \u001b[39m=\u001b[39m i \u001b[39m#节点选择的方法\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m#进行攻击,输出攻击日志\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# 1. 节点选择，返回攻击的节点\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m ack_map \u001b[39m=\u001b[39m node_map(i,chi_k,out_K, cfgin, GSNet_Model, test_loader, risk_mask, road_adj, risk_adj, poi_adj,\n\u001b[1;32m     37\u001b[0m                     grid_node_map, device, data_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnyc\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     38\u001b[0m \u001b[39m# 2. 攻击方法选择，返回未攻击后的预测值，标签值,攻击前的预测值，攻击过程打印每个信息\u001b[39;00m\n\u001b[1;32m     39\u001b[0m adv_val_predict, val_target, val_predict \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(parm_att))(logger, cfgin, ack_map, GSNet_Model, test_loader,  road_adj, risk_adj, poi_adj,\n\u001b[1;32m     40\u001b[0m                                                                         grid_node_map, scaler, risk_mask, device, data_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnyc\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/mycode/attack_gsnet/Attack-accident-prediction/lib/Imperceptible_attack.py:800\u001b[0m, in \u001b[0;36mnode_map\u001b[0;34m(select_name, chi_k, out_K, cfgs, net, dataloader, risk_mask, road_adj, risk_adj, poi_adj, grid_node_map, device, data_type)\u001b[0m\n\u001b[1;32m    798\u001b[0m opt_saliency\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    799\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m--> 800\u001b[0m     loss_saliency \u001b[39m=\u001b[39m ten_loss(net(X_saliency, target_time, graph_feature, road_adj, risk_adj, poi_adj,\n\u001b[1;32m    801\u001b[0m                                       grid_node_map), chi_k, device)\u001b[39m#12是风险最高的前12个区域\u001b[39;00m\n\u001b[1;32m    802\u001b[0m loss_saliency\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    803\u001b[0m inputs_grad \u001b[39m=\u001b[39m X_saliency\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mycode/attack_gsnet/Attack-accident-prediction/model/GSNet.py:258\u001b[0m, in \u001b[0;36mGSNet.forward\u001b[0;34m(self, grid_input, target_time_feature, graph_feature, road_adj, risk_adj, poi_adj, grid_node_map)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39mArguments:\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m    grid_input {Tensor} -- grid input，shape：(batch_size,T,D,W,H)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39m    {Tensor} -- shape：(batch_size,pre_len,north_south_map,west_east_map)\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m batch_size,_,_,_,_ \u001b[39m=\u001b[39mgrid_input\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 258\u001b[0m grid_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mst_geo_module(grid_input,target_time_feature)\n\u001b[1;32m    259\u001b[0m graph_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mst_sem_module(graph_feature,road_adj,risk_adj,poi_adj,\n\u001b[1;32m    260\u001b[0m                                 target_time_feature,grid_node_map)\n\u001b[1;32m    262\u001b[0m grid_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_weigth(grid_output)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mycode/attack_gsnet/Attack-accident-prediction/model/GSNet.py:90\u001b[0m, in \u001b[0;36mSTGeoModule.forward\u001b[0;34m(self, grid_input, target_time_feature)\u001b[0m\n\u001b[1;32m     84\u001b[0m conv_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_conv(grid_input)\n\u001b[1;32m     86\u001b[0m conv_output \u001b[39m=\u001b[39m conv_output\u001b[39m.\u001b[39mview(batch_size,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,D,W,H)\\\n\u001b[1;32m     87\u001b[0m                 \u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)\\\n\u001b[1;32m     88\u001b[0m                 \u001b[39m.\u001b[39mcontiguous()\\\n\u001b[1;32m     89\u001b[0m                 \u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,T,D)\n\u001b[0;32m---> 90\u001b[0m gru_output,_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrid_gru(conv_output)\n\u001b[1;32m     92\u001b[0m grid_target_time \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(target_time_feature,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m,W\u001b[39m*\u001b[39mH,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mview(batch_size\u001b[39m*\u001b[39mW\u001b[39m*\u001b[39mH,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     93\u001b[0m grid_att_fc1_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_att_fc1(gru_output))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:942\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    941\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    943\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    944\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    946\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.91 GiB (GPU 0; 10.76 GiB total capacity; 6.83 GiB already allocated; 2.52 GiB free; 7.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "import yaml\n",
    "from mmcv import Config\n",
    "from lib.myfunction import log_test_results\n",
    "from lib.Imperceptible_attack import log_test_csv,node_map\n",
    "from lib.Imperceptible_attack import ZINBSC,min_impr,pgd_impr,random_impr,log_test_csv_time_K\n",
    "from lib.myfunction import get_root_logger, logger_info,kl_div_pro\n",
    "\n",
    "#配置logo\n",
    "logger = get_root_logger('INFO', './logdata')\n",
    "logger.info(\"Loading config file from \")\n",
    "cfgin = Config.fromfile('attack_setting.yaml')\n",
    "#根据配置选择攻击方法\n",
    "if cfgin.attacker == 'white_attacker':\n",
    "    header = ['time','epoch','dataset', 'model','node_select', 'method', 'K','batch size', \n",
    "              'clean_RMSE', 'clean_recall', 'clean_MAP', 'clean_RCR',\n",
    "              'adv_RMSE', 'adv_recall', 'adv_MAP', 'adv_RCR',\n",
    "              'local_adv_RMSE', 'local_adv_recall', 'local_adv_MAP', 'local_adv_RCR',\n",
    "              '备注信息：特征分析，50']\n",
    "    #文件名\n",
    "    file_name = '28-{}-eps{}-model-{}'.format(\n",
    "        cfgin.dataset, cfgin.test_epsilon, cfgin.backbone)\n",
    "    log_test_results(cfgin.result_dir, header, file_name)\n",
    "    #可能的时间循环\n",
    "    #攻击方法+节点选择组合\n",
    "    for epoch in range(3):\n",
    "        #break\n",
    "        for out_K in cfgin.K:\n",
    "            for i in cfgin.select_node:\n",
    "                for j in cfgin.attack_method:\n",
    "                    for chi_k in range(35,36):\n",
    "                        logger.info(i+'_'+j+\"_\"+str(out_K)+\"_\"+str(chi_k))\n",
    "                        parm_att = j #攻击方法的函数名称\n",
    "                        parm_node = i #节点选择的方法\n",
    "                        #进行攻击,输出攻击日志\n",
    "                        # 1. 节点选择，返回攻击的节点\n",
    "                        ack_map = node_map(i,chi_k,out_K, cfgin, GSNet_Model, test_loader, risk_mask, road_adj, risk_adj, poi_adj,\n",
    "                                            grid_node_map, device, data_type='nyc')\n",
    "                        # 2. 攻击方法选择，返回未攻击后的预测值，标签值,攻击前的预测值，攻击过程打印每个信息\n",
    "                        adv_val_predict, val_target, val_predict = eval(\"{0}\".format(parm_att))(logger, cfgin, ack_map, GSNet_Model, test_loader,  road_adj, risk_adj, poi_adj,\n",
    "                                                                                                grid_node_map, scaler, risk_mask, device, data_type='nyc')\n",
    "                        #计算结果并打印、存储,注意表头信息需要传递参数\n",
    "                        log_test_csv_time_K(epoch,out_K,adv_val_predict, val_target,\n",
    "                                            val_predict,cfgin,i,j,file_name,risk_mask)\n",
    "                        torch.cuda.empty_cache()\n",
    "    for epoch in range(1):\n",
    "        for out_K in [20,30,40]:\n",
    "            i = 'ten'\n",
    "            j = 'ZINBSC'\n",
    "            for chi_k in range(26,45):\n",
    "                logger.info(i+'_'+j+\"_\"+str(out_K)+\"_\"+str(chi_k))\n",
    "                parm_att = j #攻击方法的函数名称\n",
    "                parm_node = i #节点选择的方法\n",
    "                #进行攻击,输出攻击日志\n",
    "                # 1. 节点选择，返回攻击的节点\n",
    "                ack_map = node_map(i,chi_k,out_K, cfgin, GSNet_Model, test_loader, risk_mask, road_adj, risk_adj, poi_adj,\n",
    "                                    grid_node_map, device, data_type='nyc')\n",
    "                # 2. 攻击方法选择，返回未攻击后的预测值，标签值,攻击前的预测值，攻击过程打印每个信息\n",
    "                adv_val_predict, val_target, val_predict = eval(\"{0}\".format(parm_att))(logger, cfgin, ack_map, GSNet_Model, test_loader,  road_adj, risk_adj, poi_adj,\n",
    "                                                                                        grid_node_map, scaler, risk_mask, device, data_type='nyc')\n",
    "                #计算结果并打印、存储,注意表头信息需要传递参数\n",
    "                log_test_csv_time_K(epoch,out_K,adv_val_predict, val_target,\n",
    "                                    val_predict,cfgin,i,j,file_name,risk_mask)\n",
    "                torch.cuda.empty_cache()\n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
